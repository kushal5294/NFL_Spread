{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80299b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c47ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rk                   Tm     G     PA     Yds     Ply  Y/P    TO    FL  \\\n",
      "0  1.0     Baltimore Ravens  17.0  280.0  5123.0  1109.0  4.6  31.0  13.0   \n",
      "1  2.0   Kansas City Chiefs  17.0  294.0  4926.0  1045.0  4.7  17.0   9.0   \n",
      "2  3.0  San Francisco 49ers  17.0  298.0  5167.0  1038.0  5.0  28.0   6.0   \n",
      "3  4.0        Buffalo Bills  17.0  311.0  5222.0  1015.0  5.1  30.0  12.0   \n",
      "4  5.0       Dallas Cowboys  17.0  315.0  5095.0  1014.0  5.0  26.0   9.0   \n",
      "\n",
      "    1stD  ...   Yds.2  TD.1  Y/A  1stD.2    Pen  Yds.3  1stPy   Sc%   TO%  \\\n",
      "0  306.0  ...  1860.0   6.0  4.5    96.0  106.0  841.0   35.0  28.7  14.4   \n",
      "1  300.0  ...  1925.0  10.0  4.5   107.0   73.0  604.0   24.0  28.5   9.5   \n",
      "2  319.0  ...  1525.0  10.0  4.1    97.0   94.0  762.0   32.0  33.9  15.5   \n",
      "3  313.0  ...  1880.0  14.0  4.6    96.0   99.0  753.0   34.0  32.0  16.0   \n",
      "4  311.0  ...  1910.0  14.0  4.2   108.0  104.0  934.0   37.0  32.0  14.6   \n",
      "\n",
      "      EXP  \n",
      "0  107.53  \n",
      "1   37.02  \n",
      "2   16.05  \n",
      "3   15.23  \n",
      "4   32.08  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loop through years\n",
    "    #Read in csvs\n",
    "year = \"2023\"\n",
    "    #Remove redundant columns\n",
    "df = pd.read_csv(f\"{year}Def.csv\")\n",
    "print(df.head())\n",
    "df = df.drop('G', axis = 'columns')\n",
    "df = df.drop('PA', axis = 'columns')\n",
    "df = df.drop('Cmp', axis = 'columns')\n",
    "df = df.drop('Att', axis = 'columns')\n",
    "df = df.drop('Yds.1', axis = 'columns')\n",
    "df = df.drop('TD', axis = 'columns')\n",
    "df = df.drop('Int', axis = 'columns')\n",
    "df = df.drop('NY/A', axis = 'columns')\n",
    "df = df.drop('Att.1', axis = 'columns')\n",
    "df = df.drop('Yds.2', axis = 'columns')\n",
    "df = df.drop('TD.1', axis = 'columns')\n",
    "df = df.drop('Y/A', axis = 'columns')\n",
    "df = df.rename(columns = {'Yds': 'Yds_tot', '1stD': '1stD_tot', '1stD.1': '1stD_Pss', '1stD.2': '1stD_Rsh', 'Yds.3': 'Yds_Pny'})\n",
    "of = pd.read_csv(f\"{year}Off.csv\")\n",
    "of = of.drop('G', axis = 'columns')\n",
    "of = of.drop('PF', axis = 'columns')\n",
    "of = of.drop('Cmp', axis = 'columns')\n",
    "of = of.drop('Att', axis = 'columns')\n",
    "of = of.drop('Yds.1', axis = 'columns')\n",
    "of = of.drop('TD', axis = 'columns')\n",
    "of = of.drop('Int', axis = 'columns')\n",
    "of = of.drop('NY/A', axis = 'columns')\n",
    "of = of.drop('Att.1', axis = 'columns')\n",
    "of = of.drop('Yds.2', axis = 'columns')\n",
    "of = of.drop('TD.1', axis = 'columns')\n",
    "of = of.drop('Y/A', axis = 'columns')\n",
    "of = of.rename(columns = {'Yds': 'Yds_tot', '1stD': '1stD_tot', '1stD.1': '1stD_Pss', '1stD.2': '1stD_Rsh', 'Yds.3': 'Yds_Pny'})\n",
    "\n",
    "dfPass = pd.read_csv(f\"{year}PassingDef.csv\")\n",
    "ofPass = pd.read_csv(f\"{year}PassingOff.csv\")\n",
    "dfRush = pd.read_csv(f\"{year}RushingDef.csv\")\n",
    "dfRush.drop('G', axis = 'columns')\n",
    "ofRush = pd.read_csv(f\"{year}RushingOff.csv\")\n",
    "ofRush.drop('G', axis = 'columns')\n",
    "dfScor = pd.read_csv(f\"{year}ScoringDef.csv\")\n",
    "ofScor = pd.read_csv(f\"{year}ScoringOff.csv\")\n",
    "\n",
    "#NOTE: Overall has different name for team column\n",
    "standings = pd.read_csv(f\"{year}NFLDATA_overall.csv\")\n",
    "\n",
    "#Merge csvs\n",
    "offCSV = pd.merge(ofPass, ofRush, on = \"Tm\", suffixes=(\"_Pss\", \"_Rsh\"))\n",
    "\n",
    "#num_rows, num_columns = offCSV.shape\n",
    "#print (num_rows)\n",
    "#print (num_columns)\n",
    "offCSV = pd.merge(of, offCSV, on = \"Tm\")\n",
    "offCSV = pd.merge(offCSV, ofScor, on = \"Tm\")\n",
    "offCSV = offCSV.dropna(subset=['Tm'])\n",
    "\n",
    "defCSV = pd.merge(dfPass, dfRush, on = \"Tm\", suffixes=(\"_Pss\", \"_Rsh\"))\n",
    "defCSV = pd.merge(df, defCSV, on = \"Tm\")\n",
    "defCSV = pd.merge(defCSV, dfScor, on = \"Tm\")\n",
    "defCSV = defCSV.dropna(subset=['Tm'])\n",
    "\n",
    "outputCSV = pd.merge(offCSV, defCSV, on = \"Tm\", suffixes=(\"_Off\", \"_Def\"))\n",
    "outputCSV = pd.merge(standings, outputCSV, left_on = \"Tm\", right_on = \"Tm\")\n",
    "outputCSV['Tm'] = outputCSV['Tm']+\"_2023\"\n",
    "outputCSV = outputCSV.fillna(0)\n",
    "\n",
    "\n",
    "#Print out that year's csv\n",
    "outputCSV.to_csv(f\"{year}_all_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f3059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.read_csv(\"2023Schedule.csv\")\n",
    "sample_data_df = pd.read_csv(\"2023_all_stats.csv\")\n",
    "merged_df = pd.merge(scores_df, sample_data_df, left_on=\"Away\", right_on=\"Tm\", how=\"left\")\n",
    "merged_df = pd.merge(merged_df, sample_data_df, left_on=\"Home\", right_on=\"Tm\", suffixes=(\"_away\", \"_home\"), how=\"left\")\n",
    "merged_df = merged_df.rename(columns={'A': 'New_A', 'B': 'New_B'})\n",
    "week = 19\n",
    "merged_df.to_csv(f\"Week{week}Test.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5e499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
